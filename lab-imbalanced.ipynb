{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with Credit Card Fraud dataset.\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "- **distance_from_home:** the distance from home where the transaction happened.\n",
    "- **distance_from_last_transaction:** the distance from last transaction happened.\n",
    "- **ratio_to_median_purchase_price:** Ratio of purchased price transaction to median purchase price.\n",
    "- **repeat_retailer:** Is the transaction happened from same retailer.\n",
    "- **used_chip:** Is the transaction through chip (credit card).\n",
    "- **used_pin_number:** Is the transaction happened by using PIN number.\n",
    "- **online_order:** Is the transaction an online order.\n",
    "- **fraud:** Is the transaction fraudulent. **0=legit** -  **1=fraud**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.091079</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.247564</td>\n",
       "      <td>5.600044</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.190936</td>\n",
       "      <td>0.566486</td>\n",
       "      <td>2.222767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_from_home  distance_from_last_transaction  \\\n",
       "0           57.877857                        0.311140   \n",
       "1           10.829943                        0.175592   \n",
       "2            5.091079                        0.805153   \n",
       "3            2.247564                        5.600044   \n",
       "4           44.190936                        0.566486   \n",
       "\n",
       "   ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                        1.945940              1.0        1.0   \n",
       "1                        1.294219              1.0        0.0   \n",
       "2                        0.427715              1.0        0.0   \n",
       "3                        0.362663              1.0        1.0   \n",
       "4                        2.222767              1.0        1.0   \n",
       "\n",
       "   used_pin_number  online_order  fraud  \n",
       "0              0.0           0.0    0.0  \n",
       "1              0.0           0.0    0.0  \n",
       "2              0.0           1.0    0.0  \n",
       "3              0.0           1.0    0.0  \n",
       "4              0.0           1.0    0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraud\n",
      "0.0    0.912597\n",
      "1.0    0.087403\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(df[\"fraud\"].value_counts(normalize=True))\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fraud_prop= (df[\"fraud\"].value_counts(normalize=True).rename(\"proportion\").reset_index())\n",
    "fraud_prop.columns=[\"fraud\",\"prop\"]\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.barplot(data=fraud_prop,x=\"fraud\",y=\"prop\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.xlabel(\"Fraud (0 = no, 1 = yes)\")\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95875\n",
      "ROC-AUC 0.9668931031140444\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.98    182557\n",
      "         1.0       0.89      0.60      0.72     17443\n",
      "\n",
      "    accuracy                           0.96    200000\n",
      "   macro avg       0.93      0.80      0.85    200000\n",
      "weighted avg       0.96      0.96      0.96    200000\n",
      "\n",
      "Confusion matrix [[181283   1274]\n",
      " [  6976  10467]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n",
    "\n",
    "features = df.drop(columns=[\"fraud\"])\n",
    "target = df[\"fraud\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "y_proba = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC-AUC\", roc_auc_score(y_test, y_proba))\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion matrix\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93469\n",
      "ROC-AUC: 0.9795556683011314\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.93      0.96    182557\n",
      "         1.0       0.58      0.95      0.72     17443\n",
      "\n",
      "    accuracy                           0.93    200000\n",
      "   macro avg       0.79      0.94      0.84    200000\n",
      "weighted avg       0.96      0.93      0.94    200000\n",
      "\n",
      "Confusion matrix: [[170347  12210]\n",
      " [   852  16591]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "over = RandomOverSampler(random_state=42)\n",
    "X_train_over, y_train_over = over.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "log_reg_over = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "log_reg_over.fit(X_train_over, y_train_over)\n",
    "\n",
    "y_pred_over = log_reg_over.predict(X_test_scaled)\n",
    "y_proba_over = log_reg_over.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_over))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_over))\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_over))\n",
    "print(\"Confusion matrix:\", confusion_matrix(y_test, y_pred_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93448\n",
      "ROC-AUC: 0.979540310967081\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.93      0.96    182557\n",
      "         1.0       0.58      0.95      0.72     17443\n",
      "\n",
      "    accuracy                           0.93    200000\n",
      "   macro avg       0.79      0.94      0.84    200000\n",
      "weighted avg       0.96      0.93      0.94    200000\n",
      "\n",
      "Confusion matrix:\n",
      " [[170295  12262]\n",
      " [   842  16601]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "under = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_train_under, y_train_under = under.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "log_reg_under = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "log_reg_under.fit(X_train_under, y_train_under)\n",
    "\n",
    "y_pred_under = log_reg_under.predict(X_test_scaled)\n",
    "y_proba_under = log_reg_under.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_under))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_under))\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_under))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SMOTE ===\n",
      "Accuracy: 0.934645\n",
      "ROC-AUC: 0.9795620551784171\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.93      0.96    182557\n",
      "         1.0       0.58      0.95      0.72     17443\n",
      "\n",
      "    accuracy                           0.93    200000\n",
      "   macro avg       0.79      0.94      0.84    200000\n",
      "weighted avg       0.96      0.93      0.94    200000\n",
      "\n",
      "Confusion matrix:\n",
      " [[170334  12223]\n",
      " [   848  16595]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "log_reg_smote = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "log_reg_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_pred_smote = log_reg_smote.predict(X_test_scaled)\n",
    "y_proba_smote = log_reg_smote.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_smote))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_smote))\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_smote))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_smote))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After resampling (over-, under-sampling and SMOTE), accuracy drops slightly but recall for the fraud class jumps from about 0.60 to 0.95, and ROC-AUC improves, meaning the model detects many more fraudulent transactions.\n",
    "\n",
    "This trade-off is desirable in fraud detection: we accept more false positives in exchange for missing far fewer fraud cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1.** What is the distribution of our target variable? Can we say we're dealing with an imbalanced dataset?\n",
    "- **2.** Train a LogisticRegression.\n",
    "- **3.** Evaluate your model. Take in consideration class importance, and evaluate it by selection the correct metric.\n",
    "- **4.** Run **Oversample** in order to balance our target variable and repeat the steps above, now with balanced data. Does it improve the performance of our model? \n",
    "- **5.** Now, run **Undersample** in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model?\n",
    "- **6.** Finally, run **SMOTE** in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
